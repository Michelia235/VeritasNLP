{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yanJEg8ZyDi"
   },
   "source": [
    "# Môn học: Xử lý Ngôn ngữ Tự nhiên (HK2 24-25)\n",
    "Giảng viên: ThS. Huỳnh Thanh Sơn\n",
    "# Thành viên nhóm:\n",
    "* Trần Trọng Kiên (MSSV: 22110093)\n",
    "* Trương Hồng Kiệt (MSSV: 22110096)\n",
    "* Vũ Diệu Minh (MSSV: 22110118)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFCzIBshcHmg"
   },
   "source": [
    "# **Final Project**\n",
    "\n",
    "##**Problem stament :**     \n",
    "\n",
    "The widespread dissemination of fake news and propaganda presents serious societal risks, including the erosion of public trust, political polarization, manipulation of elections, and the spread of harmful misinformation during crises such as pandemics or conflicts. From an NLP perspective, detecting fake news is fraught with challenges. Linguistically, fake news often mimics the tone and structure of legitimate journalism, making it difficult to distinguish using surface-level features. The absence of reliable and up-to-date labeled datasets, especially across multiple languages and regions, hampers the effectiveness of supervised learning models. Additionally, the dynamic and adversarial nature of misinformation means that malicious actors constantly evolve their language and strategies to bypass detection systems. Cultural context, sarcasm, satire, and implicit bias further complicate automated analysis. Moreover, NLP models risk amplifying biases present in training data, leading to unfair classifications and potential censorship of legitimate content. These challenges underscore the need for cautious, context-aware approaches, as the failure to address them can inadvertently contribute to misinformation, rather than mitigate it.\n",
    "\n",
    "\n",
    "\n",
    "Use datasets in link : https://drive.google.com/drive/folders/1mrX3vPKhEzxG96OCPpCeh9F8m_QKCM4z?usp=sharing\n",
    "to complete requirement.\n",
    "\n",
    "## **About dataset:**\n",
    "\n",
    "* **True Articles**:\n",
    "\n",
    "  * **File**: `MisinfoSuperset_TRUE.csv`\n",
    "  * **Sources**:\n",
    "\n",
    "    * Reputable media outlets like **Reuters**, **The New York Times**, **The Washington Post**, etc.\n",
    "\n",
    "* **Fake/Misinformation/Propaganda Articles**:\n",
    "\n",
    "  * **File**: `MisinfoSuperset_FAKE.csv`\n",
    "  * **Sources**:\n",
    "\n",
    "    * **American right-wing extremist websites** (e.g., Redflag Newsdesk, Breitbart, Truth Broadcast Network)\n",
    "    * **Public dataset** from:\n",
    "\n",
    "      * Ahmed, H., Traore, I., & Saad, S. (2017): \"Detection of Online Fake News Using N-Gram Analysis and Machine Learning Techniques\" *(Springer LNCS 10618)*\n",
    "\n",
    "\n",
    "\n",
    "## **Requirement**\n",
    "\n",
    "A team consisting of three members must complete a project that involves applying the methods learned from the beginning of the course up to the present. The team is expected to follow and document the entire machine learning workflow, which includes the following steps:\n",
    "\n",
    "1. **Data Preprocessing**: Clean and prepare the dataset,etc.\n",
    "\n",
    "2. **Exploratory Data Analysis (EDA)**: Explore and visualize the data.\n",
    "\n",
    "3. **Model Building**: Select and build one or more machine learning models suitable for the problem at hand.\n",
    "\n",
    "4. **Hyperparameter set up**: Set and adjust the model's hyperparameters using appropriate methods to improve performance.\n",
    "\n",
    "5. **Model Training**: Train the model(s) on the training dataset.\n",
    "\n",
    "6. **Performance Evaluation**: Evaluate the trained model(s) using appropriate metrics (e.g., accuracy, precision, recall, F1-score, confusion matrix, etc.) and validate their performance on unseen data.\n",
    "\n",
    "7. **Conclusion**: Summarize the results, discuss the model's strengths and weaknesses, and suggest possible improvements or future work.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rU9L4Sd8_NLE"
   },
   "source": [
    "# 0. Thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H-iAysVW_Jyb",
    "outputId": "44660810-a761-4ac1-d1fd-59081a4b1278"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade git+https://github.com/huggingface/datasets.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nUqTPUZBsEzs"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import gdown\n",
    "import zipfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    BertTokenizer, BertForSequenceClassification,\n",
    "    XLNetTokenizer, XLNetForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay, confusion_matrix, roc_curve, auc\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import gc\n",
    "import psutil\n",
    "from typing import List\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kiPgpyX-sDp5"
   },
   "source": [
    "# 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "id": "5UB1vzAIsVHT",
    "outputId": "5f51a36c-a207-4c14-f4f5-e6b11826c559"
   },
   "outputs": [],
   "source": [
    "file_id = \"1BhaOQU5wYDL8IxOzgvZM-IlgYfJf3HFD\"\n",
    "output = \"true.zip\"\n",
    "gdown.download(id=file_id, output=output, quiet=False)\n",
    "\n",
    "file_id = \"1aA9o8PJ-9gYAcLaaxLmXUrxlrHtArlrh\"\n",
    "output = \"fake.zip\"\n",
    "gdown.download(id=file_id, output=output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZYV1TsdtKvH"
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(\"true.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"true\")\n",
    "\n",
    "with zipfile.ZipFile(\"fake.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"fake\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ct9RwcJSumQH"
   },
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wRRvTen1c8x"
   },
   "source": [
    "Đọc dữ liệu từ hai file csv, tạo thêm cột label tương ứng và kết hợp hai data frame với nhau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "Kkkgu2yhtiA5",
    "outputId": "b695e9de-3424-405a-a7b2-0e170b08d1fb"
   },
   "outputs": [],
   "source": [
    "df_true = pd.read_csv(\"/content/true/DataSet_Misinfo_TRUE.csv\", usecols=['text'])\n",
    "df_fake = pd.read_csv(\"/content/fake/DataSet_Misinfo_FAKE.csv\",usecols=['text'])\n",
    "\n",
    "df_true['label'] = 1\n",
    "df_fake['label'] = 0\n",
    "\n",
    "df = pd.concat([df_true, df_fake], ignore_index=True)\n",
    "\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "display(df.sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKxsmuSJ2aAZ"
   },
   "source": [
    "Kiểm tra dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "id": "1jgYaIVL2VJR",
    "outputId": "c192b1ee-a28c-4370-ff7d-cf65cb0bfbc4"
   },
   "outputs": [],
   "source": [
    "# Data analysis\n",
    "\n",
    "# Datatype\n",
    "print(\"Datatype of each column:\")\n",
    "print(df.info())\n",
    "print(\"====\"*25)\n",
    "\n",
    "# Null checking\n",
    "print(\"Null value:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"====\"*25)\n",
    "\n",
    "# Duplicate checking\n",
    "print(\"Duplicate:\")\n",
    "print(df.duplicated().sum())\n",
    "print(\"====\"*25)\n",
    "\n",
    "# Number of each target class\n",
    "sns.countplot(data=df, x='label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I8AgPwyu4Vyo"
   },
   "source": [
    "Sau khi kiểm tra, ta thấy dữ liệu bị khuyết ở 29 dòng và bị lặp 10012, do đó ta thực hiện tiền xử lý dữ liệu:\n",
    "* Xoá các dòng bị khuyết\n",
    "* Xoá các dòng bị lặp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OInfbsNY3H5P"
   },
   "outputs": [],
   "source": [
    "def preprocessing_data(df):\n",
    "    df = df.dropna(inplace=False)\n",
    "    df = df.drop_duplicates(inplace=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "untwbF4v5gGE",
    "outputId": "03e86273-890f-44a2-be42-e4136d5871e3"
   },
   "outputs": [],
   "source": [
    "df = preprocessing_data(df.copy())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhnLub_b6SIJ"
   },
   "source": [
    "## Khám phá dữ liệu (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2tLB-kD5xGA"
   },
   "source": [
    "### Kiểm tra lại phân phối của hai lớp sau khi tiền xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "GjWyFS0D5wxI",
    "outputId": "b560fb13-30c5-4c8e-f5d4-8cd5a38a1d08"
   },
   "outputs": [],
   "source": [
    "class_counts = df['label'].value_counts().sort_index()\n",
    "print(\"Class distribution:\")\n",
    "print(class_counts)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x=class_counts.index, y=class_counts.values)\n",
    "plt.xticks([0,1], ['Fake','True'])\n",
    "plt.title('Number of Samples per Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8y3u5T6kD06J"
   },
   "source": [
    "### Thống kê tóm tắt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TZIeSn1t9-Dp"
   },
   "outputs": [],
   "source": [
    "df['char_len'] = df['text'].apply(len) # Character lengths\n",
    "df['word_len'] = df['text'].apply(lambda x: len(x.split())) # Word lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OYeXTwii-Kz5",
    "outputId": "4b208231-81bf-49da-f374-f07c48819a1f"
   },
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(df.groupby('label')[['char_len','word_len']].describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4H2vCrnV-cb-"
   },
   "source": [
    "Dựa vào bảng thống kê tóm tắt, ta có thể rút ra một số nhận xét quan trọng về khác biệt giữa hai nhóm \"Fake\" (label 0) và \"True\" (label 1):\n",
    "\n",
    "1. **Kích thước trung bình**\n",
    "\n",
    "   * Độ dài tính theo ký tự (char\\_len): trung bình Fake ~ 2 573 ký tự, True ~ 3 245 ký tự.\n",
    "   * Độ dài tính theo số từ (word\\_len): trung bình Fake ~ 427 từ, True ~ 537 từ.\n",
    "\n",
    "     -> Các bài true nhìn chung dài hơn hẳn so với fake (hơn \\~25 % về số từ), điều này có thể cho thấy rằng tin thật thường được khai thác nội dung sâu hơn, chi tiết hơn.\n",
    "\n",
    "2. **Phân bố và độ lệch**\n",
    "\n",
    "   * Độ lệch chuẩn (std) của cả hai lớp đều khá lớn (hơn 3 000 ký tự / hơn 500 từ), cho thấy có độ đa dạng cao về độ dài bài. Tuy nhiên lớp Fake có độ lệch chuẩn về char\\_len còn cao hơn so với lớp True, nghĩa là độ dài các bài fake rất không đồng đều: có những bài cực kỳ ngắn (min = 1 ký tự) và cũng có những bài rất dài (max = 142 961 ký tự).\n",
    "   * Range của lớp Fake cũng dài hơn (từ 1 tới 142 961 ký tự) so với True (3 tới 85 948 ký tự).\n",
    "\n",
    "3. **Percentiles**\n",
    "\n",
    "   * **25%**: 25% bài Fake có $\\leq$ 589 ký tự (\\~97 từ), trong khi 25% bài True đã có $\\geq$ 1 109 ký tự (\\~181 từ).\n",
    "   * **50% (median)**: bài Fake giữa nhóm dài \\~1 976 ký tự (331 từ), bài True \\~2 408 ký tự (391 từ).\n",
    "   * **75%**: 75% bài Fake $\\leq$ 3 058 ký tự (509 từ), nhưng 75% bài True $\\leq$ 4 397 ký tự (725 từ).\n",
    "     \n",
    "     -> Nhìn vào median và quartiles, toàn bộ phân vị của lớp True đều cao hơn lớp Fake, minh chứng mạnh mẽ cho việc bài True thường dài hơn, nội dung dày dặn hơn.\n",
    "\n",
    "4. **Outliers**\n",
    "\n",
    "   * Cả hai lớp đều có outliers (những bài cực ngắn hoặc cực dài). Những bài cực ngắn (1–3 từ) khả năng là noise hoặc lỗi (ví dụ record trống hoặc chỉ tiêu đề). Những bài cực dài (đến cả chục nghìn từ) có thể gây ảnh hưởng lớn lên vector hóa TF-IDF và cả thời gian train.\n",
    "\n",
    "**Kết luận & gợi ý xử lý tiếp**\n",
    "\n",
    "* Có sự khác biệt rõ ràng về độ dài giữa fake và true, vì thế ta có thể cân nhắc đưa độ dài văn bản như một feature phụ để hỗ trợ phân loại.\n",
    "* Loại hoặc giới hạn outliers:\n",
    "\n",
    "  * Loại bỏ những bài quá ngắn (< 10 từ) vì rất có thể không chứa đủ thông tin.\n",
    "  * Giới hạn độ dài tối đa (cắt mẫu xuống về ngưỡng 95th percentile) để tránh ảnh hưởng tới model.\n",
    "\n",
    "* Khi xây dựng mô hình, ngoài TF-IDF ta có thể thử thêm feature numeric “char\\_len” và “word\\_len” để xem có giúp cải thiện hiệu quả phân loại không.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eS6ocTDG6LD"
   },
   "source": [
    "### Trực quan hoá dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6B8mA60HC7K"
   },
   "source": [
    "#### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "id": "kzsV0k6M51x_",
    "outputId": "bf92a8a7-7de1-4029-ad79-27e081ecb57b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.histplot(df, x='char_len', hue='label', bins=50, element='step')\n",
    "plt.title('Char Length Distribution')\n",
    "plt.subplot(1,2,2)\n",
    "sns.histplot(df, x='word_len', hue='label', bins=50, element='step')\n",
    "plt.title('Word Count Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYozuQYR9ctI"
   },
   "source": [
    "Biểu đồ histogram cho ta hình dung về sự phân bố độ dài của văn bản (theo ký tự và theo số từ) cho hai lớp:\n",
    "\n",
    "1. **Đặc điểm chung**\n",
    "\n",
    "   * Cả hai lớp đều có phân bố lệch phải (right skewed), tức là hầu hết bài nằm ở phần độ dài ngắn, rồi giảm dần tần suất khi độ dài tăng lên.\n",
    "   * Cả hai biểu đồ đều có đuôi dài kéo tận các giá trị rất cao, nghĩa là vẫn có một số bài cực dài nhưng rất ít.\n",
    "\n",
    "2. **So sánh Fake (label 0) vs True (label 1)**\n",
    "\n",
    "   * Ở bên trái (độ dài nhỏ), cột của Fake thường cao hơn True, tức là bài giả chiếm tỉ lệ lớn hơn ở nhóm cực ngắn.\n",
    "   * Phần đỉnh của Fake nằm ở khoảng vài trăm đến \\~1 000 ký tự (tương đương vài chục đến vài trăm từ), còn True thì đỉnh dịch sang phải hơn, khoảng 1 000–2 000 ký tự (vài trăm từ).\n",
    "   * Với độ dài trung bình cao hơn, True có nhiều bài dài hơn Fake—đỉnh và khối lượng phân bố của True kéo dài ra xa hơn bên phải so với Fake.\n",
    "\n",
    "3. **Ý nghĩa**\n",
    "\n",
    "   * Tin giả thường ngắn gọn, đôi khi chỉ vài câu, còn tin thật có xu hướng chi tiết hơn, dài hơn.\n",
    "   * Vì thế \"độ dài văn bản\" là một feature có khả năng phân biệt hai lớp: bài quá ngắn (ví dụ < 100 từ) rất có thể là tin giả, trong khi bài dài hơn (vài trăm từ trở lên) có nhiều khả năng là tin thật.\n",
    "\n",
    "Kết luận: histograms cho thấy sự khác biệt rõ ràng về phân bố độ dài giữa hai lớp, và chúng gợi ý rằng ta có thể đưa thêm các đặc trưng liên quan đến độ dài (char\\_len, word\\_len, các ngưỡng cắt) vào mô hình để cải thiện hiệu quả phân loại.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WW0KERr_HHWq"
   },
   "source": [
    "#### Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "488UAIJX9eah",
    "outputId": "7eac1717-1a9f-41c2-eaa4-fdf765eeaf64"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.boxplot(x='label', y='char_len', data=df)\n",
    "plt.xticks([0,1], ['Fake','True'])\n",
    "plt.title('Character Count Boxplot by Class')\n",
    "plt.subplot(1,2,2)\n",
    "sns.boxplot(x='label', y='word_len', data=df)\n",
    "plt.xticks([0,1], ['Fake','True'])\n",
    "plt.title('Word Count Boxplot by Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQOwBSdDJrN-"
   },
   "source": [
    "Từ boxplot, ta có thêm một số nhận xét về dữ liệu:\n",
    "\n",
    "1. **IQR và median**\n",
    "\n",
    "   * Cả hai lớp đều có median và IQR tương tự với những con số quan sát được ở bảng thống kê tóm tắt: IQR của lớp True cao hơn so với lớp Fake, khẳng định lớp True dài hơn Fake ở phần trung tâm dữ liệu.\n",
    "\n",
    "2. **Outliers**\n",
    "\n",
    "   * Từ hình ảnh được trực quan hoá, ta thấy cả hai lớp đều có rất nhiều outliers:\n",
    "\n",
    "     * Lớp Fake có số outliers ký tự vượt 100 000—những bài cực dài rất hiếm.\n",
    "     * Lớp True cũng có outliers nhưng ít hơn.\n",
    "   * Điều này gợi ý rằng cần xem xét cắt bớt hoặc xử lý outliers trước khi train mô hình, để tránh ảnh hưởng quá đáng vào TF-IDF hoặc các thuật toán nhạy với giá trị lớn.\n",
    "\n",
    "3. **Phân biệt lớp**\n",
    "\n",
    "   * Mặc dù có nhiều outliers, nhưng IQR của hai lớp vẫn tách biệt rõ:\n",
    "\n",
    "     * Fake: IQR char\\_len khoảng \\[\\~600, \\~3 000], word\\_len khoảng \\[\\~100, \\~500].\n",
    "     * True: IQR char\\_len khoảng \\[\\~1 100, \\~4 400], word\\_len khoảng \\[\\~180, \\~725].\n",
    "   * Điều này cho thấy feature \"độ dài văn bản\" có thể là một đặc trưng tốt để phân biệt hai lớp, vì khoảng IQR của chúng gần như không chồng nhiều lên nhau.\n",
    "\n",
    "**Kết luận**:\n",
    "\n",
    "Boxplot nhấn mạnh thêm rằng:\n",
    "\n",
    "* Tin thật có độ dài tập trung về giá trị lớn hơn tin giả.\n",
    "* Cần xử lý outliers trước khi vector hóa hoặc thêm feature length.\n",
    "* Độ dài văn bản là feature tiềm năng để cải thiện mô hình phân loại.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6ZTUTZQMIgd"
   },
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkJja5ngMOQK"
   },
   "source": [
    "Trong bước này, ta sẽ xử lý dữ liệu để có thể đưa vào các mô hình phân loại:\n",
    "* Loại bỏ một số outlier dựa trên percentiles (9-92 %) của cả `char_len` và `word_len`\n",
    "\n",
    "Sau đó, ta có thể:\n",
    "* Làm sạch văn bản (clean text):\n",
    "  * Lowercasing\n",
    "  * Loại bỏ URL và HTML tags\n",
    "* Tokenization (cho các mô hình transformer) & Stop‐word removal\n",
    "* Vector hoá bằng Tf-idf để chuẩn bị đưa vào mô hình Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IF4UaNY6P6C0"
   },
   "source": [
    "### Loại bỏ outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6sEyNnHHLf5v",
    "outputId": "736c3cb2-9b6b-4312-8dcc-72e2014f6c75"
   },
   "outputs": [],
   "source": [
    "lower_pct = 0.09\n",
    "upper_pct = 0.92\n",
    "char_low, char_high = df['char_len'].quantile([lower_pct, upper_pct])\n",
    "word_low, word_high = df['word_len'].quantile([lower_pct, upper_pct])\n",
    "print(f\"Removing char_len outside [{char_low:.0f}, {char_high:.0f}] and word_len outside [{word_low:.0f}, {word_high:.0f}]\")\n",
    "# Filter\n",
    "mask = (\n",
    "    df['char_len'].between(char_low, char_high) &\n",
    "    df['word_len'].between(word_low, word_high)\n",
    ")\n",
    "df = df[mask].reset_index(drop=True)\n",
    "print(f\"Samples after outlier removal: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMFW1Sd3Q700"
   },
   "source": [
    "#### Histogram sau khi xử lý outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "id": "k59NavA1Qy5v",
    "outputId": "6a874333-fe3e-4921-b61a-4add57a54b3b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.histplot(df, x='char_len', hue='label', bins=50, element='step')\n",
    "plt.title('Char Length Distribution')\n",
    "plt.subplot(1,2,2)\n",
    "sns.histplot(df, x='word_len', hue='label', bins=50, element='step')\n",
    "plt.title('Word Count Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjSnrtm6RQIr"
   },
   "source": [
    "Có thể thấy hiện tại sau khi xử lý outlier, ta thấy rằng:\n",
    "* Trước kia hist có khoảng (range) kéo dài hàng chục ngàn ký tự / hàng nghìn từ; giờ đuôi chỉ vươn tới ~8 000 ký tự và ~1 300 từ. Những giá trị cực đoan (vô cùng dài hoặc vô cùng ngắn) đã bị loại.\n",
    "* Phân bố hai lớp giờ xịch hơn về biên độ giá trị: Fake chủ yếu nằm trong ~200–3 000 ký tự (tương đương ~20–500 từ), True trong ~500–4 000 ký tự (khoảng ~50–700 từ).\n",
    "* Đỉnh của hai lớp vẫn khác nhau (đỉnh Fake nằm thấp hơn, True dịch sang phải) nhưng khoảng chung giữa chúng thu hẹp, giúp trực quan so sánh dễ hơn.\n",
    "* Bỏ bớt cực đoan giúp TF‑IDF không bị ảnh hưởng bởi những bài quá dài hay quá ngắn (vốn có thể mang nhiều từ hiếm hoặc quá lặp).\n",
    "* Việc này cũng làm rõ hơn khoảng phân biệt độ dài trung bình giữa fake và true, từ đó feature “length” có thể phát huy tác dụng tốt hơn.\n",
    "* Cả hai biểu đồ vẫn lệch phải (right‑skewed), tức đa số bài ngắn hơn, số ít kéo dài hơn. Điều này phù hợp với thực tế: nhiều tiêu đề / tin ngắn, một số bài giải thích chi tiết.\n",
    "\n",
    "**Kết luận**: bước lọc outliers đã làm cho phân phối độ dài gọn gàng, bớt “nhiễu” cực đoan nhưng vẫn giữ được khác biệt về trung bình và mode giữa Fake/True. Đây là tiền đề tốt để đưa feature độ dài vào mô hình hoặc tiến hành vector hóa TF‑IDF mà không phải lo xử lý giá trị ngoại lai nữa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "if-VGeCOShxb"
   },
   "source": [
    "#### Boxplot sau khi xử lý outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "DxzUV95mRNni",
    "outputId": "ab7b99b1-7310-4392-c9df-da2f32baa893"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.boxplot(x='label', y='char_len', data=df)\n",
    "plt.xticks([0,1], ['Fake','True'])\n",
    "plt.title('Character Count Boxplot by Class')\n",
    "plt.subplot(1,2,2)\n",
    "sns.boxplot(x='label', y='word_len', data=df)\n",
    "plt.xticks([0,1], ['Fake','True'])\n",
    "plt.title('Word Count Boxplot by Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tnCzgx7Szej"
   },
   "source": [
    "Dễ thấy rằng đã xoá được rất nhiều giá trị ngoại lai."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iAoXXdldS83s"
   },
   "source": [
    "#### Kiểm tra lại phân phối lớp sau khi xử lý outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "yaartHckS6jJ",
    "outputId": "275ac857-2f60-44d7-e1dc-46c5f17afaed"
   },
   "outputs": [],
   "source": [
    "class_counts = df['label'].value_counts().sort_index()\n",
    "print(\"Class distribution:\")\n",
    "print(class_counts)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x=class_counts.index, y=class_counts.values)\n",
    "plt.xticks([0,1], ['Fake','True'])\n",
    "plt.title('Number of Samples per Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L4LihrNMmNxN"
   },
   "outputs": [],
   "source": [
    "# get stopwords list\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser','ner'])\n",
    "stop_words = nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_41QKHGvVIQ"
   },
   "source": [
    "# 2. DatasetLoader cho Fake News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PXvIlZspvQVZ"
   },
   "outputs": [],
   "source": [
    "def print_memory_usage(stage):\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem = process.memory_info().rss / (1024 ** 3)\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU Memory allocated: {torch.cuda.memory_allocated() / (1024**2):.2f} MB\")\n",
    "    print(f\"Memory usage at {stage}: {mem:.2f} GB\")\n",
    "\n",
    "class FakeNewsDatasetLoader:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.train = None\n",
    "        self.val = None\n",
    "        self.test = None\n",
    "\n",
    "    def load(self, df):\n",
    "\n",
    "        train_df, test_df = train_test_split(\n",
    "            df, test_size=0.2, stratify=df['label'], random_state=42\n",
    "        )\n",
    "        train_df, val_df = train_test_split(\n",
    "            train_df, test_size=0.15, stratify=train_df['label'], random_state=42\n",
    "        )\n",
    "\n",
    "        def df_to_dict_safe(df):\n",
    "            \"\"\"Convert DataFrame to dict while handling numpy 2.x compatibility\"\"\"\n",
    "            result = {}\n",
    "            for col in df.columns:\n",
    "                if df[col].dtype == 'object':\n",
    "                    result[col] = df[col].astype(str).tolist()\n",
    "                else:\n",
    "                    result[col] = df[col].astype(int).tolist()\n",
    "            return result\n",
    "\n",
    "        self.train = Dataset.from_dict(df_to_dict_safe(train_df))\n",
    "        self.val   = Dataset.from_dict(df_to_dict_safe(val_df))\n",
    "        self.test  = Dataset.from_dict(df_to_dict_safe(test_df))\n",
    "\n",
    "        del train_df, val_df, test_df; gc.collect()\n",
    "        return self.train, self.val, self.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORjqhAAovZnk"
   },
   "source": [
    "# 3. Tiền xử lý văn bản\n",
    "Làm sạch văn bản"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ayKRTGR7vakg"
   },
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self):\n",
    "        self.html_tag = re.compile(r'<[^>]+>')\n",
    "        self.whitespace = re.compile(r'\\s+')\n",
    "\n",
    "    def clean_text(self, texts):\n",
    "        is_single = isinstance(texts, str)\n",
    "        texts = [texts] if is_single else texts\n",
    "        return [self._clean_single_text(text) for text in texts]\n",
    "\n",
    "    def _clean_single_text(self, text):\n",
    "        text = str(text)\n",
    "        text = self.html_tag.sub('', text)\n",
    "        text = self.whitespace.sub(' ', text)\n",
    "        return text.strip().lower()\n",
    "\n",
    "    def preprocess(self, dataset: Dataset) -> Dataset:\n",
    "        return dataset.map(\n",
    "            lambda x: {'text': self.clean_text(x['text'])},\n",
    "            batched=True,\n",
    "            batch_size=1000,\n",
    "            num_proc=5,\n",
    "            desc=\"Cleaning texts\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FKY0LKKZvkJo"
   },
   "source": [
    "# 4. Tokenizer (cho các mô hình transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FmDceqAAvoya"
   },
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, model_name, max_length):\n",
    "        self.model_name = model_name\n",
    "        self.max_length = max_length\n",
    "\n",
    "        if 'distilbert' in model_name:\n",
    "            self.tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "        elif 'bert' in model_name:\n",
    "            self.tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
    "        elif 'xlnet' in model_name:\n",
    "            self.tokenizer = XLNetTokenizer.from_pretrained(model_name)\n",
    "            self.tokenizer.padding_side = 'left'\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "\n",
    "    def tokenize(self, dataset: Dataset) -> Dataset:\n",
    "        if 'label' in dataset.column_names:\n",
    "            if 'distilbert' in self.model_name or 'bert' in self.model_name:\n",
    "                dataset = dataset.rename_column(\"label\", \"labels\")\n",
    "            elif 'xlnet' in self.model_name:\n",
    "                pass\n",
    "\n",
    "        # Sử dụng num_proc=1 để ổn định\n",
    "        tokenized = dataset.map(\n",
    "            self._tokenize_batch,\n",
    "            batched=True,\n",
    "            remove_columns=['text'],\n",
    "            num_proc=5,\n",
    "            desc=\"Tokenizing texts\"\n",
    "        )\n",
    "\n",
    "        if 'distilbert' in self.model_name or 'bert' in self.model_name:\n",
    "            required_columns = ['input_ids', 'attention_mask', 'labels']\n",
    "        else:  # XLNet\n",
    "            required_columns = ['input_ids', 'attention_mask', 'label']\n",
    "\n",
    "        tokenized.set_format(\n",
    "            'torch',\n",
    "            columns=required_columns,\n",
    "            output_all_columns=False\n",
    "        )\n",
    "\n",
    "        return tokenized\n",
    "\n",
    "    def _tokenize_batch(self, examples):\n",
    "        return self.tokenizer(\n",
    "            examples['text'],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=('bert' in self.model_name)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4OW6sPxvwYx"
   },
   "source": [
    "# 5. DataLoader Creator (cho transformer models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aBCWL1BdvwhM"
   },
   "outputs": [],
   "source": [
    "class DataLoaderCreator:\n",
    "    def __init__(self, hp):\n",
    "        self.batch_size = hp.batch_size\n",
    "        self.shuffle_flags = {\n",
    "            'train': True,\n",
    "            'val': False,\n",
    "            'test': False\n",
    "        }\n",
    "\n",
    "    def create(self, datasets):\n",
    "        return {\n",
    "            split: DataLoader(\n",
    "                dataset,\n",
    "                batch_size=self.batch_size,\n",
    "                shuffle=self.shuffle_flags[split],\n",
    "                num_workers=0,\n",
    "                pin_memory=True\n",
    "            )\n",
    "            for split, dataset in datasets.items()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlipX1aYv4eo"
   },
   "source": [
    "# 6. Xây dựng mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P_VPnSeiv3-4"
   },
   "outputs": [],
   "source": [
    "class ModelBuilder:\n",
    "    @staticmethod\n",
    "    def build(hp):\n",
    "        # Xử lý các mô hình transformer\n",
    "        if 'distilbert' in hp.model_name:\n",
    "            try:\n",
    "                model = DistilBertForSequenceClassification.from_pretrained(\n",
    "                    hp.model_name,\n",
    "                    num_labels=1\n",
    "                )\n",
    "            except OSError:\n",
    "                model = DistilBertForSequenceClassification.from_pretrained(\n",
    "                    hp.model_name,\n",
    "                    num_labels=1,\n",
    "                    from_tf=True\n",
    "                )\n",
    "            return model\n",
    "        elif 'bert' in hp.model_name:\n",
    "            model = BertForSequenceClassification.from_pretrained(\n",
    "                hp.model_name,\n",
    "                num_labels=1,\n",
    "                hidden_dropout_prob=hp.dropout_rate,\n",
    "                attention_probs_dropout_prob=hp.dropout_rate\n",
    "            )\n",
    "            return model\n",
    "        elif 'xlnet' in hp.model_name:\n",
    "            model = XLNetForSequenceClassification.from_pretrained(\n",
    "                hp.model_name,\n",
    "                num_labels=1,\n",
    "                dropout=hp.dropout_rate\n",
    "            )\n",
    "            return model\n",
    "\n",
    "        # Xử lý các mô hình TF-IDF + Machine Learning\n",
    "        elif 'tfidf' in hp.model_name:\n",
    "            vectorizer = TfidfVectorizer(\n",
    "                max_features=hp.tfidf_max_features,\n",
    "                ngram_range=(1, 2),\n",
    "                stop_words='english'\n",
    "            )\n",
    "\n",
    "            if 'lr' in hp.model_name:\n",
    "                classifier = LogisticRegression(\n",
    "                    max_iter=1000,\n",
    "                    C=hp.tfidf_c,\n",
    "                    random_state=2305,\n",
    "                    n_jobs=-1  # Sử dụng tất cả cores\n",
    "                )\n",
    "            elif 'svm' in hp.model_name:\n",
    "                classifier = SVC(\n",
    "                    C=hp.tfidf_c,\n",
    "                    kernel='linear',\n",
    "                    probability=True,\n",
    "                    random_state=2305\n",
    "                )\n",
    "            elif 'rf' in hp.model_name:\n",
    "                classifier = RandomForestClassifier(\n",
    "                    n_estimators=100,\n",
    "                    random_state=2305,\n",
    "                    n_jobs=-1  # Sử dụng tất cả cores\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown TF-IDF model: {hp.model_name}\")\n",
    "\n",
    "            return Pipeline([\n",
    "                ('tfidf', vectorizer),\n",
    "                ('clf', classifier)\n",
    "            ])\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model type: {hp.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_mguznhwCuI"
   },
   "source": [
    "# 7. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v3y_mkUawCOv"
   },
   "outputs": [],
   "source": [
    "class Hyperparameters:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 64\n",
    "        self.max_length = 128\n",
    "        self.epochs = 10\n",
    "        self.learning_rate = 2e-5\n",
    "        self.weight_decay = 0.01\n",
    "        self.warmup_steps = 100\n",
    "        self.patience = 2\n",
    "        self.max_grad_norm = 1.0\n",
    "        self.dropout_rate = 0.2\n",
    "        self.tfidf_max_features = 5000\n",
    "        self.tfidf_c = 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRZCzKkkwMi1"
   },
   "source": [
    "# 8. Quy trình training cho transformer models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1hGhy39swMqW"
   },
   "outputs": [],
   "source": [
    "class TransformerTrainer:\n",
    "    def __init__(self, model, hp, train_loader, val_loader):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = model.to(self.device)\n",
    "        self.hp = hp\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.best_val_acc = 0\n",
    "        self.early_stop_counter = 0\n",
    "        self.patience = hp.patience\n",
    "\n",
    "        # Setup optimizer and scheduler\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=hp.learning_rate,\n",
    "            weight_decay=hp.weight_decay\n",
    "        )\n",
    "\n",
    "        total_steps = len(train_loader) * hp.epochs\n",
    "        self.scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "            self.optimizer,\n",
    "            start_factor=0.1,\n",
    "            total_iters=hp.warmup_steps\n",
    "        )\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.hp.epochs):\n",
    "            # In dòng Epoch\n",
    "            print(f\"\\nEpoch {epoch+1}/{self.hp.epochs}\")\n",
    "\n",
    "            # ——— Training loop với tqdm ———\n",
    "            self.model.train()\n",
    "            total_loss, total_correct = 0.0, 0\n",
    "            train_bar = tqdm(self.train_loader, desc=\"Training\", unit=\"batch\")\n",
    "            for batch in train_bar:\n",
    "                loss, correct = self._process_batch(batch, train=True)\n",
    "                total_loss += loss\n",
    "                total_correct += correct\n",
    "                # Cập nhật postfix (tuỳ chọn)\n",
    "                # train_bar.set_postfix(\n",
    "                #     loss=f\"{total_loss/(train_bar.n):.4f}\",\n",
    "                #     acc=f\"{total_correct/((train_bar.n)*batch['input_ids'].size(0)):.4f}\"\n",
    "                # )\n",
    "            avg_train_loss = total_loss / len(self.train_loader)\n",
    "            train_acc = total_correct / len(self.train_loader.dataset)\n",
    "\n",
    "            # ——— Validation loop với tqdm ———\n",
    "            self.model.eval()\n",
    "            val_loss, val_correct = 0.0, 0\n",
    "            val_bar = tqdm(self.val_loader, desc=\"Validation\", unit=\"batch\")\n",
    "            with torch.no_grad():\n",
    "                for batch in val_bar:\n",
    "                    loss, correct = self._process_batch(batch, train=False)\n",
    "                    val_loss += loss\n",
    "                    val_correct += correct\n",
    "                    # val_bar.set_postfix(\n",
    "                    #     loss=f\"{val_loss/(val_bar.n):.4f}\",\n",
    "                    #     acc=f\"{val_correct/((val_bar.n)*batch['input_ids'].size(0)):.4f}\"\n",
    "                    # )\n",
    "            avg_val_loss = val_loss / len(self.val_loader)\n",
    "            val_acc = val_correct / len(self.val_loader.dataset)\n",
    "\n",
    "            # In kết quả epoch\n",
    "            print(f\"[Train] Loss: {avg_train_loss:.4f} | Acc: {train_acc:.4f}\")\n",
    "            print(f\"[Val]   Loss: {avg_val_loss:.4f} | Acc: {val_acc:.4f}\")\n",
    "\n",
    "            # Early stopping & lưu model\n",
    "            if val_acc > self.best_val_acc:\n",
    "                self.best_val_acc = val_acc\n",
    "                self.early_stop_counter = 0\n",
    "                self.best_model_path = f\"best_{self.hp.model_name.replace('/', '_')}.pt\"\n",
    "                torch.save(self.model.state_dict(), self.best_model_path)\n",
    "                print(f\"New best model saved (Val Acc: {val_acc:.4f})\")\n",
    "            else:\n",
    "                self.early_stop_counter += 1\n",
    "                print(f\"No improvement for {self.early_stop_counter}/{self.patience} epochs\")\n",
    "                if self.early_stop_counter >= self.patience:\n",
    "                    print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                    break\n",
    "\n",
    "        if not hasattr(self, 'best_model_path'):\n",
    "            self.best_model_path = f\"final_{self.hp.model_name.replace('/', '_')}.pt\"\n",
    "            torch.save(self.model.state_dict(), self.best_model_path)\n",
    "            print(f\"Saved final model to {self.best_model_path}\")\n",
    "\n",
    "        print_memory_usage(\"After training\")\n",
    "\n",
    "    def _process_batch(self, batch, train):\n",
    "        inputs = {\n",
    "            'input_ids': batch['input_ids'].to(self.device),\n",
    "            'attention_mask': batch['attention_mask'].to(self.device),\n",
    "            'labels': batch.get('labels', batch.get('label')).to(self.device).float()\n",
    "        }\n",
    "        outputs = self.model(**inputs)\n",
    "        loss = outputs.loss if hasattr(outputs, 'loss') else nn.BCEWithLogitsLoss()(outputs.logits.squeeze(), inputs['labels'])\n",
    "\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(self.model.parameters(), self.hp.max_grad_norm)\n",
    "            self.optimizer.step(); self.optimizer.zero_grad(); self.scheduler.step()\n",
    "\n",
    "        logits = outputs.logits\n",
    "        preds = (torch.sigmoid(logits) > 0.5).int().squeeze()\n",
    "        correct = (preds == inputs['labels'].int()).sum().item()\n",
    "\n",
    "        return loss.item(), correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yultrKYxwf51"
   },
   "source": [
    "# 9. Quy trình training cho TF-IDF + ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZzTCZp-SwgHE"
   },
   "outputs": [],
   "source": [
    "class TFIDFTrainer:\n",
    "    def __init__(self, model, hp, X_train, y_train, X_val, y_val):\n",
    "        self.model = model\n",
    "        self.hp = hp\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.best_model = None\n",
    "\n",
    "    def train(self):\n",
    "        print(\"\\nTraining TF-IDF model...\")\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "        val_acc = self.model.score(self.X_val, self.y_val)\n",
    "        print(f\"[Validation] Accuracy: {val_acc:.4f}\")\n",
    "        self.best_model = self.model\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        test_acc = self.best_model.score(X_test, y_test)\n",
    "        y_pred = self.best_model.predict(X_test)\n",
    "\n",
    "        print(\"\\nTest Results:\")\n",
    "        print(f\"Accuracy: {test_acc:.4f}\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        return {\n",
    "            'accuracy': test_acc,\n",
    "            'report': classification_report(y_test, y_pred, output_dict=True)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BszHVc0owakc"
   },
   "source": [
    "# 10. Evaluator (cho transformer models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JwCEYQZkwau7"
   },
   "outputs": [],
   "source": [
    "class TransformerEvaluator:\n",
    "    @staticmethod\n",
    "    def evaluate(model, test_loader, device, model_name):\n",
    "        if 'distilbert' in model_name or 'bert' in model_name:\n",
    "            label_key = 'labels'\n",
    "        else:  # XLNet\n",
    "            label_key = 'label'\n",
    "\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        all_probs = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "                inputs = {\n",
    "                    'input_ids': batch['input_ids'].to(device),\n",
    "                    'attention_mask': batch['attention_mask'].to(device)\n",
    "                }\n",
    "                labels = batch[label_key].to(device)\n",
    "                outputs = model(**inputs)\n",
    "\n",
    "                logits = outputs.logits if hasattr(outputs, 'logits') else outputs[0]\n",
    "                probs = torch.sigmoid(logits)\n",
    "                preds = (probs > 0.5).int().cpu().numpy()\n",
    "                all_preds.extend(preds)\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "        report_dict = classification_report(all_labels, all_preds, output_dict=True)\n",
    "        acc = accuracy_score(all_labels, all_preds)\n",
    "        return {\n",
    "            'accuracy': acc,\n",
    "            'report': report_dict,\n",
    "            'preds': all_preds,\n",
    "            'labels': all_labels,\n",
    "            'probs': all_probs\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78Ej6_RpwYuE"
   },
   "source": [
    "# 11. Tích hợp cả hai phương pháp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xcfx28M8Yygc"
   },
   "outputs": [],
   "source": [
    "def get_all_sentences(dataset) -> List[str]:\n",
    "\n",
    "    all_sentence = []\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "\n",
    "        sentence = dataset[i]['text']\n",
    "        all_sentence.append(sentence)\n",
    "\n",
    "    return all_sentence\n",
    "\n",
    "def n_gram_word_frequency(sentence_list: list, n: int) -> pd.DataFrame:\n",
    "\n",
    "    count_vectorizer = CountVectorizer(ngram_range=(n,n), stop_words=list(stop_words))\n",
    "    n_grams_feature_vector = count_vectorizer.fit_transform(sentence_list)\n",
    "    feature_names = count_vectorizer.get_feature_names_out()\n",
    "    return n_grams_feature_vector, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o9oKmY6hwWRt"
   },
   "outputs": [],
   "source": [
    "# Explore top words and prepare data for training phase\n",
    "def prepare_clean_and_tfidf(hp):\n",
    "\n",
    "    # Prepare data and clean text\n",
    "    loader = FakeNewsDatasetLoader()\n",
    "    raw_train, raw_val, raw_test = loader.load(df)\n",
    "    prep = Preprocessor()\n",
    "    train_data = prep.preprocess(raw_train)\n",
    "    val_data = prep.preprocess(raw_val)\n",
    "    test_data = prep.preprocess(raw_test)\n",
    "\n",
    "    # Explore top 10 most popular and rarest words using uni-gram (stopwords removed)\n",
    "    list_all_sentence: list = get_all_sentences(train_data) + get_all_sentences(val_data) + get_all_sentences(test_data)\n",
    "    print(f\"Texts within the dataset: {len(list_all_sentence)}\")\n",
    "    print(f\"Example text: {list_all_sentence[7]}\")\n",
    "\n",
    "    n_grams_feature_vector, feature_names = n_gram_word_frequency(sentence_list=list_all_sentence, n=1)\n",
    "    counts = np.asarray(n_grams_feature_vector.sum(axis=0)).ravel()\n",
    "    word_dict = dict(zip(feature_names, counts))\n",
    "\n",
    "    pop_10 = sorted(word_dict.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "    print(\"\\nTop 10 từ phổ biến nhất (uni‑gram, đã loại bỏ stopwords):\")\n",
    "    for rank, (word, freq) in enumerate(pop_10, start=1):\n",
    "        print(f\"{rank}. '{word}': {freq} lần\")\n",
    "\n",
    "    rare_10 = sorted(word_dict.items(), key=lambda x: x[1])[:10]\n",
    "\n",
    "    print(\"\\nTop 10 từ hiếm nhất (uni‑gram, đã loại bỏ stopwords):\")\n",
    "    for rank, (word, freq) in enumerate(rare_10, start=1):\n",
    "        print(f\"{rank}. '{word}': {freq} lần\")\n",
    "\n",
    "    del list_all_sentence, n_grams_feature_vector, feature_names, counts, word_dict; gc.collect()\n",
    "\n",
    "    # Prepare data to train ML model using Tfidf vectorize\n",
    "    X_train, y_train = train_data['text'], train_data['label']\n",
    "    X_val,   y_val   = val_data['text'],   val_data['label']\n",
    "    X_test,  y_test  = test_data['text'],  test_data['label']\n",
    "\n",
    "    return (X_train, y_train, X_val, y_val, X_test, y_test), train_data, val_data, test_data\n",
    "\n",
    "# Run experiments for ML models using Tfidf vectorize\n",
    "def run_tfidf_experiments(hp, tfidf_data):\n",
    "\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = tfidf_data\n",
    "    results = {}\n",
    "\n",
    "    for model_name in ['tfidf_lr', 'tfidf_rf']:\n",
    "\n",
    "        hp.model_name = model_name\n",
    "        hp.tfidf_c = 0.1 if 'lr' in model_name or 'svm' in model_name else 1.0\n",
    "        model = ModelBuilder.build(hp)\n",
    "        trainer = TFIDFTrainer(model, hp, X_train, y_train, X_val, y_val)\n",
    "        trainer.train()\n",
    "        results[model_name] = trainer.evaluate(X_test, y_test)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run experiments for transformer models\n",
    "def run_transformer_experiments(hp, train_data, val_data, test_data):\n",
    "\n",
    "    results = {}\n",
    "    for model_name in ['bert-base-uncased','distilbert-base-uncased','xlnet-base-cased', ]:\n",
    "\n",
    "        hp.model_name = model_name\n",
    "        if 'distilbert' in model_name:\n",
    "            hp.batch_size = 32\n",
    "\n",
    "        # Tokenize cleaned data\n",
    "        tokenizer = Tokenizer(model_name, hp.max_length)\n",
    "        print(\"\\nTokenizing data...\")\n",
    "        train = tokenizer.tokenize(train_data)\n",
    "        val   = tokenizer.tokenize(val_data)\n",
    "        test  = tokenizer.tokenize(test_data)\n",
    "        print_memory_usage(\"After tokenization\")\n",
    "\n",
    "        # Create loaders and train\n",
    "        loader_creator = DataLoaderCreator(hp)\n",
    "        dataloaders = loader_creator.create({\n",
    "            'train': train,\n",
    "            'val': val,\n",
    "            'test': test\n",
    "        })\n",
    "\n",
    "        print(\"\\nDataLoaders created:\")\n",
    "        print(f\"Train batches: {len(dataloaders['train'])}\")\n",
    "        print(f\"Val batches: {len(dataloaders['val'])}\")\n",
    "        print(f\"Test batches: {len(dataloaders['test'])}\")\n",
    "\n",
    "        # Build model\n",
    "        model = ModelBuilder.build(hp)\n",
    "        print(f\"\\nModel architecture: {model.__class__.__name__}\")\n",
    "\n",
    "        # Training\n",
    "        trainer = TransformerTrainer(\n",
    "            model=model,\n",
    "            hp=hp,\n",
    "            train_loader=dataloaders['train'],\n",
    "            val_loader=dataloaders['val']\n",
    "        )\n",
    "\n",
    "        print(\"\\nStarting training...\")\n",
    "        trainer.train()\n",
    "\n",
    "        # Evaluating\n",
    "        if trainer.best_model_path and os.path.exists(trainer.best_model_path):\n",
    "            model.load_state_dict(torch.load(trainer.best_model_path))\n",
    "\n",
    "        print(\"\\nEvaluating on test set...\")\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        res = TransformerEvaluator.evaluate(\n",
    "            model=model,\n",
    "            test_loader=dataloaders['test'],\n",
    "            device=device,\n",
    "            model_name=hp.model_name\n",
    "        )\n",
    "\n",
    "        results[model_name] = res\n",
    "\n",
    "        print(\"\\nTest Results:\")\n",
    "        print(f\"Accuracy: {res['accuracy']:.4f}\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(\n",
    "            res['labels'],\n",
    "            res['preds'],\n",
    "            target_names=['Fake','True'],\n",
    "            digits=4\n",
    "        ))\n",
    "\n",
    "        # Plot Confusion Matrix\n",
    "        cm = confusion_matrix(res['labels'], res['preds'])\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                      display_labels=['Fake','True'])\n",
    "        fig_cm, ax_cm = plt.subplots()\n",
    "        disp.plot(ax=ax_cm, values_format='d')\n",
    "        ax_cm.set_title(f\"Confusion Matrix: {model_name}\")\n",
    "        plt.show()\n",
    "\n",
    "        # Plot ROC Curve and AUC\n",
    "        fpr, tpr, _ = roc_curve(res['labels'], res['probs'])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        fig_roc, ax_roc = plt.subplots()\n",
    "        ax_roc.plot(fpr, tpr)\n",
    "        ax_roc.plot([0,1], [0,1])\n",
    "        ax_roc.set_xlabel('False Positive Rate')\n",
    "        ax_roc.set_ylabel('True Positive Rate')\n",
    "        ax_roc.set_title(f\"ROC Curve: {model_name} (AUC = {roc_auc:.4f})\")\n",
    "        plt.show()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZH8z_y4wPSy"
   },
   "source": [
    "# 12. Hàm main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "2e48da5571eb44208811f4d5a5b71b40",
      "22f0aeb1d88b450c8f354cd7f6ce0b2c",
      "93e8695e92154abc9cba30f269d99e1c",
      "578551fa14bd4579b3b9a46a82eb007e",
      "3e82e742ac7a400995c74c504fcaff51",
      "20d4e24f685c4c11945a99021733a9d6",
      "b77ae8f8522d4b8099eda93ab321d529",
      "e38c93014f10410e9b349f347a295d1c",
      "88e02e5f1fb5403f9621b73d90dffb0b",
      "4079b9804e12478b90bacf00a0c657b7",
      "cc73dc46c87a4f8d8fa8ba6f0d6a8528",
      "fa59a5a48ab443cd98832d01cc3e3a84",
      "626602b3d0924db39fd786496c233e5d",
      "c1d9d43e732d4568a682344cddb7549a",
      "b6af47fa827a44e194877bf8483c60db",
      "9fa21424f68542d78c3ce57b144309e7",
      "7cc628adee064e6eb14a4f95a6bcf782",
      "d8a0153350c842efbfe382225de30b17",
      "235d6e40a8bb4830b0b81ec9fc3f5ff5",
      "d0397a35497a4dabb79f7840f465c287",
      "11facaa1a28b4c19ab8b746fed7fff09",
      "847f8f18a6954dcdad110b021db234a8",
      "8911759aac814d5c9633dad769e86e02",
      "0bb85f5266644e27a78245be66725e1a",
      "e9108be9ec2146b9901d7e8a6b75f4ac",
      "b4d9a16dff9a4b47884dea536a50af79",
      "e6c5f3de58bb4a01be887871dfde73d4",
      "60fa623227bb444ebd21ad767ae6d232",
      "978957e1b0a54d17baab0032ff349d4b",
      "2cd948d115434feda80d99b333d401ce",
      "896821dc71274df7a38b845ba1952ea1",
      "bc1778600aff48df99709db75775ff3d",
      "a5eadd506b604e85a0bfaf57cb6014b2",
      "87d7b9a4caa74610b528de21eac9ced8",
      "07e48252a5af474a95acecd87a9e5dee",
      "8cb54234fac74044a7b939f9c01db164",
      "792240644e284580a22620572e7153cb",
      "e33a2caae0144df2955fcecf8aa1aa39",
      "81ee97a6168b46d2b812e279d52a3f61",
      "35826642526c4230a0878eba348e4350",
      "674a9d93f49f4ca7b82b796fc08a4818",
      "925a1e2804124c30bc32a6806ffbd27c",
      "3ada1ca798f649cc91e2aa2cfd924473",
      "1fc157a912fb4f27a8b5f9497aa42ef8",
      "41f9010133ff4777b728eb33683e5798",
      "a21edf2eb6c54f9e8e5b468efaeff0e9",
      "7683fceaa7cd4fa0979d89f553433158",
      "5c7244b38373485681112db7ba1d940e",
      "7df7d7709f0e428695727ed6cce0195c",
      "47ea2444965541b9a02c7a4fb765e175",
      "e775d911b46541e38a0c38112bd9c2df",
      "2e83b7dc5c2a414b8b98cc58ce0e9069",
      "47b4ddf37101499a96f9dcf1eb064b63",
      "537cdba4e115474386f1de87107b420f",
      "3272632a7ab94f99bb2b632474310aba",
      "1d1d2614f673449db4978f72e9a1f5ae",
      "65d47633d5754bfa9bacffe29ce64ece",
      "811e0af747f049158b309959cc923f53",
      "5f85c8c2196a45d38d6be0ed4be1e3f7",
      "a6c0a0a3804340a5b305b3dc90167bff",
      "b007499680ec403d99f8f53c507bdf20",
      "22c5545d03324e35880970ea2d283da3",
      "acf5079e694147169ca72b1818f478d5",
      "bdefe29fde17475cb449ae032a5f57f6",
      "c8b83968975d46fd9c062baff677eef5",
      "5619e6b91c3d40adaa791e54e9751f01",
      "129122ae756044bab4ec8a03717f50f0",
      "cbaa240d01364c0b868b5d58a9766302",
      "63cb846b078c4955943c35bbdee1f044",
      "44f69fdb7d1f495c8dd0cee363b1a38b",
      "66a3f4e0c22c485cae2ca3466944f599",
      "20a1900f9f7340c2b11360e505c4a2f2",
      "e84700b168874e9ca681bf8f1c332c51",
      "c5b72a7680db459084b422978e9bf15b",
      "cdd7ac1898fc48f183ad0868d1997b85",
      "2aaf565852564c31b69d7965265170d5",
      "8eaf0131f4c8485595d3ee0ec9d57596",
      "573213391ece46b4b155695460bd052a",
      "ca1f7209834a4054882fa78bb39eaf95",
      "2ca7c721f1834e08bf1156f0f15a28bb",
      "d843ad672a70421c8abdcb7938488538",
      "d5fb5a20c40342a9b6b00a9cec97238e",
      "c6e84fa1764b4a2f82c0257f86824b39",
      "149e1d8bb0cc40839c93d8107c8b394e",
      "fcb5f20a7a7d4dc1b06aa4897a5585b3",
      "89fe01235b324cbdb19c8de9ff4254dc",
      "90837e761bbf418d9562b24c6fc44303",
      "fb7803cc559b482cbd182ce7b96e9e08",
      "a3167be0fabd4aecb60be32aa34cd0fb",
      "be40ded38f944874bbc4cbd84fa84cc2",
      "bfd7755c71b04d169ebae8c991e4b158",
      "217e405491f64d6e9081c85aa17920c9",
      "6645310e39bd481e822d192684d8ed71",
      "e9a30a09311a4555b93e1fe25e563037",
      "db2381f011144f0dbe085ef97ec63215",
      "7d5114d2d9504e628b09412d1009af9e",
      "13016882c10d49919c520e38e9da0612",
      "c29b1eecb5624b45a12a0914375fb1fa",
      "784d9e7e0b204f32b794f1b6b98f1834",
      "7d45535de2714a129f1fc8bb0dd70c95",
      "d062c9a5831a4ed4874f571a2f4d26f0",
      "73a6a396cd32439c8f846f8ef3694832",
      "4a076d1533cb443ca8776896e8dc8a82",
      "c0e860afee644cf0bb7252dc53971179",
      "eccee0ab96d941c08352014396a0c2fc",
      "edee5c4343bb4b359b8c09db08870c94",
      "0ade51a597514bda85dd9697ac341cf4",
      "0a9e7bc94fe044ab846f0caacd27f89b",
      "c7304b90439a461888866c5e427e3673",
      "fb5869e01a874fed901fa4414ed73587",
      "c195bac997774e80a2735ae35d106d22",
      "a5e99134605644b489066a468a783ecf",
      "d1c42f8b773048a78dc7ae70de7e5295",
      "de59683c821f4f438e4026b14e2f8522",
      "e771865249184df3a464ba5a9da31dd2",
      "dafb9533c33a46e6b808f02cf43910d9",
      "a53f392392d24760ae8d801f9d0498ee",
      "4be2d98034ec4a45b023dc36559e5360",
      "2b0026f23bf84fc58def17355fc22f3f",
      "e8a8e6e9193e47419aa651e2715ace8a",
      "a7576b966d8b41ebb30c7c8dfa094c3c",
      "763baf12a6544e71b0ad0573ca39076b",
      "e53aad440c6d4629934d487932fab5fc",
      "137524cd8c0c4ef8a4c69a6627379094",
      "6a450cf6ca374bb5bfcae49a256ff3e5",
      "f3f256dc5b1f4a2083b4b1da646e9555",
      "9cb2d04dd9ef487688d9a1bb5aa06ba7",
      "255add1051d34be190d957709c5872c4",
      "4096a490ed0c491ba0eed314c1cf339f",
      "4fb7e67e2a0244f788e409e07737a320",
      "7b28a42b4fba4287858c9cc1da01577f",
      "c530de743ec24f01a07bd07f99a1fcaa",
      "e43b8fe8bd3e401f8fd8945be0f0134f",
      "f11f778960a3416cba0049171eced544",
      "ffd5b17ccd9b40df99fedf31958c7e63",
      "3065b70b8e474b5daf2d312562cfa494",
      "158de6f753724a2d94519fda9b3d9958",
      "4ed93ba391204a96b5cc28b77a04e587",
      "7acf7424efd24393882943e57101c94a",
      "dd1f127539c440e8aba246db58f82cd6",
      "7c61b45d61fc48a79f37c0d387d1232e",
      "9fcb7da3acd24aacbc5b3bd7e4c3430b",
      "c7745ff26ce248ebaab32907aa2ee8df",
      "effa5aaefddf4e109c1b912d5d0b3b0c",
      "291a8731ec4449c88583263ac508fba3",
      "3428bd530b7548d196c75b9c13aac091",
      "2bec23d8b3ec4204b884d88c6d29021c",
      "17d6c21f59cc4efa994df497ba6e0da9",
      "19bebb14bdc44ce59e56c04f7889ab0b",
      "78572056ac7240b6ae46964c8eb7be39",
      "316b797097a9487dba617461912e1607",
      "8fccc247247e4207af1dbba814732e58",
      "dfa6e647924645c0950ba0b8b09bb5e1",
      "3e1f13f8883b4c5a969d2480203635fd",
      "b85932674eae4683ba4a074d08f958d1",
      "3d971502dc4f4c0fadea195b0546fd42",
      "0e3120d32c61416597be826dff76fe80",
      "7c6232d1ae3c458d99ea01d6c129aaf4",
      "445133929294422bba169a78c334ddf7",
      "de66c48243f9400388c0849ff2a427a9",
      "4c7276c4e1394b8c98a89c417f3caf52",
      "75db549ffc274029892f51517c66d9ad",
      "9e3486a8dcc24acfa9d1e02e4b5d07d1",
      "376010cc69cc4d18ad052b59059f45e0",
      "1aff17ff4b7d4468a2a8b2bc0a6afede",
      "5160c89f52904398b1f4b6bd87dc5ce0",
      "c3e2db4acdd14d498bab61133688d42d",
      "38db9b41731245aba6f8e5e4cb142c12",
      "b55a6e7c25594f379b572d59b31b87b4",
      "1c3a562590b044afbdb2fc7b5a75f6be",
      "4ae30c2676b24354ad6c3ad6ea64e22d",
      "a7f910a8e62840af90438c1255d8e268",
      "68b263cf42c246fa9e00a613b50a69f4",
      "1321be415a5d4d74b202e1c9831556a0",
      "9f3a97a60f9b4cf9b62f73ef3466a928",
      "d66b0757630a4d32b2093087f0e181cf",
      "f813d17f31634309b8daefe487eafb8c",
      "45dd338fc6cb452fbb4dc6c976c29f8b",
      "3a4905f419f04545b79d0b8f6bb24bcc",
      "19af2fdc27e04265b81a02f9642cb574",
      "7343ff8a104c47b5b79a89fb03815672",
      "c0b025a216924371ab39a3dc2cdef36e",
      "b3ce6c9bd09745e79c9642bafc0c12fb",
      "e3cefe7d83a945d28917e126bd4bda0a",
      "52c01dd8474940f7a7be506d8fab5f7e",
      "92de6e47ffab4faeb59dc2ed635c3be7",
      "97df60c06aa94214add2831ff537cd1f",
      "d5b2bc5895cd4727955ee17f1cd738a2",
      "fc79a4ed91c34bae974b5f388eb40bfb",
      "1b8b27a9dd6e4c8dbe23b3ca172045c5",
      "a365ed3c6597412ab80975ca08b79ccb",
      "1f7e0fb81c9a4594a25a526c9400c89e",
      "913037983abc433599e2f0a34590ca0e",
      "d67658261e9e4770ac910ad9caac266e",
      "69ba13b4b6324219abfad972a0c4137a",
      "cb07c72ce29946deab9f4a5196c9d6e1",
      "6c43623c453942569f9e8e5d4738946a",
      "826b0bcdfd4d4dde9373f77bb2009313",
      "92f4120669534f809a70d2bf80ff8424",
      "0a77c5e3297f4ce8a1c02846284480d2",
      "b881eb4b0dd943d88b68b3ff0f521530",
      "9424ae70860b44969f2a985b343ba22d",
      "d5f0e52956954f65882756a8b3060a8e",
      "f3cd8931cbcb4c11a2187c46f3c6acb9",
      "87d74b515f814a198d435432f0bf5b22",
      "466a377b48b64a338aa0eeded3a04967",
      "afcf52a11da64a7381c064caf8e5d034",
      "0139f369762c49d8998016f580f02adc",
      "800c4ecc3cfa491193dae3cc69da0494",
      "dd9004c1cbc64459805ed62eeb9af721",
      "5504673500464e5b9930c6c7d004d953",
      "df5b8104907f49e2883b1a71474fe224",
      "a8f1b0d9544e4b9ca9115d0f3610b294",
      "d176a5ae74194c32a4fbdb4552664a31",
      "f5ae73ad5f9b4c2b96c0ff48008edd70",
      "178f53d464594dddb896ffc1b3ea6462",
      "502df87f07a349ccb71b7b2542f42635",
      "197ed27f85634cd9a7129d37b782ac79",
      "0e6087a673024a6d8df7deed464d35db",
      "262b42b90fcf4108a90af753508ae8c8",
      "c4a32fa50d9845b68bbf76691d0dceb5",
      "1063a052d36744f599051e37dc5e1483",
      "6524c0f941e74476b594945dd2f4c208",
      "7e0788e51e3f46c79e6f0271a2b2337e",
      "2bb88e56ecca4e3797dd86f527f29ff0",
      "d70a0b74dd7d4bbaa114df1960cfc0b4",
      "49ca9ebe30d545a7bc51a6cc323dce0e",
      "7f61ad537140487fa33858da5cc92ebb",
      "021d11674f64490d82f22dd590eb8683",
      "5b2cbc67407a4dffb56f070648b250bd",
      "9bfecc52bd55491f94d6257c979b5b34",
      "7e37b80cad3d45e584658886ed04b25f",
      "7479fddec567400684b1aa87c7ff5627",
      "457d0c71e6824f70a62693220f163172",
      "5eef971ef65a41e5b43c60a06aa1062d",
      "e1f38abe3c8e42da915a7cd92afc77f0",
      "eadcfa1e01f84db3b0daca5071b78d54",
      "2279e03a3bcb415298cb64839e14afcd",
      "39267f4b267a4ddabd691fa375ad5f1c",
      "12c445a47a6b471f8e6ba5295ac5907e",
      "f961f648446c437cbc52bd4ef3391c72",
      "b198173e37e944118b5112ebdb23d72d",
      "f296038bcde84642b4203cc7c118b158",
      "8d4e9eedc23a45cd9a3c47911e52874c",
      "cb722e227c48400d89749dbebdfb8055",
      "e84e15994db243b59183783c574aa728",
      "5ebdfd3cffa24149981522d9f142bb3a",
      "29295380471a46aa8527769b6fc79948",
      "b80ce92118c74224a0df20c6e4a625c5",
      "64593699617a4f59b0f46597730f4745",
      "a53d392265374a2fa547a5dda50a7eeb",
      "3b352d8a2d504b119e9adbeaf2fc5980",
      "8ee239382a7e4349864bc266bd62ef4c",
      "5e3e562ce11d4bb09f9640a23d71ab27",
      "5a957c5d32a7466ca2c1e949b5b933c9",
      "e28183f072914685b6d58d884d5464ca",
      "2e2e865deaac431a96cba6430d2ad304",
      "68ceb923f62b46d284d8db8df1090645",
      "579cc9813485456b8d16245c017558b1",
      "e1004b4368564a62b11559bb7ce1285a",
      "eefc94ea92b848d186fef15ad623c598",
      "3d7d4b6bb4bd4c379ea6c45b627d17ee",
      "647934db75c74c4cb2ccae30a14f1378",
      "6b47b45ec83841159f7e87d90f18f7da",
      "558e084355a84efa8694e4d6268c4ce0",
      "c0267f0835cf40579146d3f7f73bad8d",
      "5fa34a6ea2684741b8b44df2fd082244",
      "85fd5566e8db42838d89281d87430786",
      "8e7e72c488424c5da83d6110f0ef93ea",
      "18612adff80849ed84d3c1cd871602cb",
      "ab16957a2687473a95b887e375d92442",
      "e7ce5dfc8a5b4cb09d0f608d78b6afa4",
      "f8b8815b0bed456f87e3623c084980de",
      "eac6fb1a4bf444a7a7617f6e5cf0a6d8",
      "5366dcbd2d154919bc521c8c1117089d",
      "e0c1052b18044ba488302e2813783322",
      "ac014e7de4924f24bd0f683371a69896",
      "dfe06085ac7b4e5a856e5a5a44f690f3",
      "347fbf8fc2c14e6aaf7e7af93fe82337",
      "4789424daaee4b11926e04e73b8eb1c5",
      "6bd211dd904749d398a4cf2c9c604a59",
      "560014aefd1643df9a444fd3f5edc301",
      "6d2c0276b15a4f2b8a12f55eb5ed8be2",
      "7b706ce33da84567a1ff27959a05efc9",
      "5e456b7f369b41a399f07f3e5083f72b",
      "5b9c2f3d5ed44cb1a074dcb2869ef2d9",
      "765c6390cfac46df8eb282a10003e0f6",
      "3923ff4bb4a447718093a813ca956d23",
      "81e2efafb3a846e887fd49afd4338a93",
      "b5ee457f4f1f4dcf82eff41349010e9b",
      "1fd4d06734c345bf8236fd437dc4b0b6",
      "1c3ce080020246e08fe1fd5322c8339f",
      "5027598abd07440699da3c6f73391579",
      "7d605d792c2a4cf1ae4237ef59b7439b",
      "6c99498593d34a8cab858ebc2269f9b3",
      "3a9ed3db78c74776a1639f78f3024f1f",
      "a915835e83094a0fa0337e6339161620",
      "ef22d1f47d40468abae92df838cd5424",
      "ccdc8486c19242b6ae9a7529c0c368cc",
      "e69af247d25949f5baa0dd311a8c8044",
      "2006d0cbbc7d4b468a853ae6e34346c1",
      "abef7fc45f9d4d6e80a41aaed2a3b80f",
      "db071d8aeb2b4c91b279afeaad118e43",
      "b8af25dccd21486bb542f131c382a8b0",
      "b7846c71d5964fd88c6805ea74f39a95",
      "188b36efcd0c46e0bcc4456d4a12c733",
      "b3672342376f4a409bf7d12e3ca55043",
      "f5f2349f210c4bafbe14232e6744f7b0",
      "481c3bc7d9464ae9bf43c710034270b1",
      "e49bcd5a34534acc8976399890f37caf",
      "0745bd30448c402899a8ba032b123ff4",
      "a6e2c09d584042a99a75660b902f99e0",
      "150c7ea48e614f2c9d8b18e877aad31f",
      "387938e5b9e84fbc92821e4841cbc72a",
      "fa9d7c82275841bfbd3e9fef763ad271",
      "d6fbcbce8dff4147acdb529f16c34e83",
      "bd14d793cf4041d1a7ec600fbb8d8b60",
      "f37db638c9a94b63a542b0de38de00b3",
      "1e57e97cebad44e68dfc09354add77b6",
      "8177e9700c664354ab51c6eae1528d73",
      "cdfa011d7e1249c4b3a82220d9ae052c",
      "15682ca7a261491a83badc877f54976a",
      "0ed43738b6b14bee9a37e7fefab607b6",
      "92e4049e958c4146a5e04501fbe0c497",
      "700c94356d4c472f9a11b76b37839825",
      "c3b52eadc2af4a9c934686bd7cfbfbb2",
      "9a985072118f4162b4424e28a75660b2",
      "5f745257a7ae4cf790babaea5005de8b",
      "e41950b7a4924f50b06df4d440c74bf1",
      "195cac7cdc6b41c4961ec119a70170d6",
      "1fd5e7057ca94736b1b7b2bbe86a80a4",
      "eea7763788314aa784ff97406ef59497",
      "d4234d21cb01444c9340b37fbde09036",
      "fdec0da9452245f3b87e7240532da91c",
      "90fe676506a149f7bbe3508d730f867f",
      "2f998a25010f46ee90354efa4b404243",
      "95c2f0f8feee441393183b8a0455df6c",
      "94c362450dc14f82a3ac38c381fe38b1",
      "17996c8f19394d6a8ba258641e2c2c3b",
      "e3bfa3b5f6ec4efd89ec801001e7e090",
      "d3846060c68e4a9e93a7d64890e63135",
      "31f830c62ee14de9b7c5cbe0e1a3530e",
      "cf861ca0fb9a4b5ebea11969b1e2dc15",
      "15f94021f5884a8694624a0d1f43d692",
      "386ab5d732b6404f9b8622d68d525093",
      "eb5b2c93494b46719980f9cc7b5dd5dd",
      "c4e3dbdcfab3458fa2ebf5e89959359f",
      "377f7794f23d4887ac45ee26001ef332",
      "7c982ec0726b46f58b0996275628cf2e",
      "2b5c3d3bdab14e15b85a2753e46cf428",
      "2bc7375f827e4e8eb6b40dffab193f27",
      "6ce996765da14836a4c1f8014eb221c8",
      "2ef01fd6bc0e4b459064ef5ad0f61387",
      "4f4bb3966ff84846b5387bee83c630bb",
      "b81c567eed2b43aa87500f20dd0f5c93",
      "d2f91593425e4447bbbc0f0d9ee7d0b3",
      "3edcea82fd894abc8dad6d09bfd45468",
      "4fb9723b80de454992043d1770c46a76",
      "33cbe103256d4076869128097ac789ab",
      "b23dfb8374664c8db5f3e271a7760950",
      "6e816018d9044e36adf55d4963369720",
      "9d956529eb814f21b2b45372d018cc30",
      "e1170f3cef6747fd87d4584df1efcd99",
      "1656c44924524eada972da7aef632a80",
      "e051cc8e602f44b3b16df9c10ada74b8",
      "62727e5170c34d0c96c315f0b29123cb",
      "26bc0ce9666c497884eb4b722ece2852",
      "3749212e362f414cb46a5f5a5a71f12d",
      "6cdc67541cbc4e518043347617af773f",
      "6356a254195846ec9fba6f31e4d48dcb",
      "501f4a18664449e3b4e0c1c3f7a6a528",
      "9f74039f6592404281caf5b2e390f8e6",
      "2c09b35d33544b3f8f6567f5e36e5d16",
      "77b67b479e76427c98d1c02e9b47c111",
      "f861db75f6de410082ad5c8bf7980dbe",
      "e659b9b82af44032b2be8f2ec6bfcf27",
      "b202199be0054fc9adc2bf529d1d090e",
      "612c33cdaca94a2199563a6f60c465f4",
      "cfa551a77e3045d28f02f0dedcf3f6b4",
      "b9e96dc2a33c41bca2c7058d8c037504",
      "edd9e80ae1b04a7691342fd0289f8daf",
      "a2973614dce84282812221fc0bd9384c",
      "6db2cbc8f30b4a74a23bc8f10785b42c",
      "52d9a3d79b784280911de210e0a6b380",
      "48f38599d631472eb1c42cd2c4420677",
      "cbb3bc3d1328425caf8cbaf6ca8e86bf",
      "ef64410a3f02411d9526a1d0f26aabbd",
      "76d0bade13ea46f8a73031c1e5c8a363",
      "af9f67c3ea6d4e8bb37f2e66f4e16577",
      "7457b635641140d9a6eac063d7c4e64e",
      "73827ca8646548a9bac4d260504ea85a",
      "27282743d30d404aabdddcb9dda33eff",
      "b2459438ea524d2e8d8e1e43f0946600",
      "c32d87f549ac40818945ea9c5814b416",
      "768b49b9fbba4580861228820c02dbef",
      "ea28772d242447efa89b69249fbc5136",
      "cde6ae2bacfc460b8b4eb5b50c988c57",
      "a3a28f5d7ae94ca0a356a0066ba0c802",
      "fc67b5075da84fa3a2ccb04ef65793ab",
      "b4182cee9f2d4cdfb35b753e7a03df68",
      "b5f396f0616042aa92a2531c08eaa212",
      "fbdb25a84c2f405cb27b7bc62bd4cf34",
      "432b4a184878406bafed9ccc04b052ec",
      "925903d6dafe4b4d9a9192d92b8cefe5",
      "24e1bd6df04e4c469543b620b568f156",
      "5f19f887b9d74b1bbe356695da44c8ac",
      "69366cf5ca71427db7d7f56bcc81682f",
      "12ab05b7fd514376b71fc70e9ae7d824",
      "f8777d3711d042caab7f0e6c5679f9dd",
      "a76e6263b12f4a668af1cca12bba7833",
      "ec5847dff1024f768eb5aae9b410fcab",
      "86d8c75ca96344bf8975ec852c379fe6",
      "895df364def24b7a9272bbb416933af5",
      "1dbf7fc13d6842fcb71af41c5b2ab8b2",
      "8e12a6278bbb43f5bff75e70347e5c94",
      "6475ce7dd7d24f29a3e89b0ff6464b0a",
      "1b25233675ec4ad69142b322779ec748",
      "66de86dc686a45b4884dc30505e9bf41",
      "1a5ca2388e9e44e197899f8b01cdbef0",
      "57b2cb48c05640dea89b504986685b4d",
      "e741739fb89f4b46bf9aa47b126baa37",
      "133a4ec6482540b888c5a5bc52634070",
      "178116c09a4645feb580fd4e83ce9d69",
      "8826f774d1444ea296f960c1db62da47",
      "6bb3c77ec760480fb9c977002f1f44b4",
      "0c0eb2b8616e4e6eb0b0ec81ac299071",
      "16ffd2c6bb874ca2892de41e4ceb911c",
      "5181ac27d3274ea09232b614f30f66da",
      "cfebbebff96b44779ff436504d98e813",
      "92b8c2ea035740bea9e54c5f1b745a26",
      "b202bd6f36864bf9a68feb9d3eb37fb9",
      "bd20229233bb494dba26e41df1bf9fc5",
      "4f18d742e7f94e08b052b666511d8de4",
      "d5c653fca13d45378fb1aa03afc91098",
      "4bd6ebd096ce4521a11dd99e57146ba7",
      "b1d4f30cbead43a88681fec212814626",
      "ecba5afcb81449e9b2bf4d5124c7e189",
      "c9114e396e00456e8c07806eb9cfa53f",
      "5a44237ac0be4caeba51f68cf687c10e",
      "4c015b93e0f3445ea2d432003045bf3c",
      "8320f4e7ee2b4bb9ae9d863dc91b0a49",
      "ff92c300e1c64dc9a972ba282eaf0ab1",
      "90936a33b656491b83c8af47e5f57603",
      "6720616ccbd6410a841aebeb6018be4b",
      "78422b3b273f4a019f96095a9f079064",
      "94b05abe9dc24c83a2784fb9ab798646",
      "9959d269bd9d4284a31e74ad073d4ec8",
      "0ca7f0ccee454c5082edc0e6fc96ceed",
      "aaa7f5629e7b4867a5b185ff0693ca47",
      "84c18eb3997c4138b720b0d22aff044b",
      "5424ffffc88144f2ac432e61f8817edd",
      "5aa04a16153c403d9751b2e9b7cfa6d2",
      "112602f38ea84a029b8d1f6897d067cd",
      "e3c8f6893f1b4f62a6d126db43a7661a",
      "53c11e02f6ee404b92b526bdf9cf3181",
      "092f189206c24242864afec0b59c4822",
      "ff034759fd3c46779a97ae0143a2df4b",
      "27385e38f54043d68de9de1de3d72dad",
      "23d8d2028aee4083bbbc55422dd295fa",
      "48a70a5c7f0f43aca4af7b2e4371b2a5",
      "ac382bcedfa74cacb1ecdb7149ed6262",
      "309a2a5813c74dae92b18dc9313732d2",
      "d1de422b16ed47548f6712ff6f4e5582",
      "dde3229f016d4f3d9b56b377a36e6357",
      "fb8006103a644400834091851bde318d",
      "6309b65943714ef3a22e8e900942bf62",
      "47be81c94941406a84486d019d604058",
      "7719797f70024e2eaff0557a3acf9fea",
      "3cc45b8146f440be9ae80a22de671285",
      "8e24d6cad96d4f4eb633c06ff1232e8c",
      "ee530ce9aeb3414185438776482bd2cf",
      "804e433f448741b3b13f161a2e23d63d",
      "3941f25c7b274b53a2782f714a1d224a",
      "d9237b4397fd45619788ac3068f82e66",
      "2357fc814a754d5c83b7a3568fdc707d",
      "bcda5367f45f4de7937b2a0c47f62e1d",
      "54e3a0295288439a9891710becafbad5",
      "babef6bf3a36483c92a62ab1d534818e",
      "82013b00695f4217b86feec823524f1f",
      "84db96d84c07443095c6c1d89958a105",
      "30332d2883ee4a21a50654b051456818",
      "b4b89b0e6611422385922c8252889b42",
      "9f182fd860484dec94e433bb4bb56af5",
      "1ad4e8bd66624f7d8d8ddbc44e517c07",
      "000efbd41f5d4c3392cf1b15d4d830f6",
      "8cbd069636bc4658ab5af626d9308617",
      "4f648403ef2d4cb39ff18b5988a9c83d",
      "7f0bb3cc1f9a40d0b229e2dd2be29284",
      "87afa80767b442c6b6ef3a807d724411",
      "10fe470a2cb64c6ebbaf7b00b5389e54",
      "36282bbdf5034e89bc8e8a9273b946f1",
      "8294fe7841b54a9da3d861c017c999b8",
      "a16b3c7a4daa483da539b495f6cbb07c",
      "f4b21295afd54d22bf42d7fbf986e201",
      "be214bc4f7184871904d1d0958ab5b21",
      "c0f49f48011a4a5694519dba114feaee",
      "b163c6c6a3544e1f8ac01f4423ad1c7e",
      "00739dc07b214523a193e6b6ee80f15a",
      "87c266c9d0644f07a3e4702264ac6880",
      "9f51147526f946b082c59719fb623213",
      "46189c9d180d460faa9daff0d6e44fde",
      "a1901c2db8f3499d863cebfd3d2ba83f",
      "145281fdd3724ed481392bb59b35497a",
      "f730ddb281114662a61a2856bd062e29",
      "39d4a9420da646cd846c2af03b5a27e7",
      "d1c1c4dec4d14b1c86ddf15d4a46bf97",
      "e99e194a3e864b09b6f0efb734a23455",
      "e296270bd55f48d69ba15c70544dcebf",
      "1b72133bba51433c98f87077b24788bd",
      "4e4a06b8a1ac492c99f698fb194d4fa3",
      "8cd1a9ce9099481db53eb871245dbe67",
      "309785cf830e4be0a41c67e808dd1b2e",
      "ad8aea0ca9cb44c5b6b2bb84936fef37",
      "8c350ba7b1934d6dac05ea703e8772fe",
      "9f530bc2db1e4dc49a0238314b7ebb7f",
      "bb1c86c1c23c45be81cc5c773813e06c",
      "3a7df3df600a44ce8aa62d8571c53055",
      "1326860d31ed4132bc42ab0e66ba307b",
      "7529ca43ee2c4bbaa992ad943d19df03",
      "f8f6d208c12240f294c21970c5a9597d",
      "abc9e246d244455e912040e2b3fb1f18",
      "f851b6eee7774958b922181a4793171a",
      "7c357b23ff1f4b818595e77fb642c27b",
      "1b18ab3604ff404ca09dc1196a89a050",
      "b0940563f99345a799fc572ba0fca0f9",
      "d0f90672622b4f569e4e9f425e44eaa4",
      "6a6ee5c8f4c54de485cb330524f20b6b",
      "477efec8c28246808ea577201a8f7917",
      "e9300e0046c34bab8363427e77e88814",
      "bcd67e807991499daf6015cf704fce78",
      "e7c448cc0fd4479dba94aaf0b55f91dc",
      "0d86b686c7684fcdb382ffbb01426e25",
      "e082d00f6bea443397956ab3aafad97e",
      "380ff141229e4640ada473176591b841",
      "85d8acbbe90048e094b66aef1cb4af95",
      "354c155eff8c4daeab7ad030b1304e6f",
      "8f8a8c0b3d6840cc906d2a9ab7152b6d",
      "eb94a2af7cf54eb1a29c61e506c2f9ca",
      "3c56da68c10f4e60991fb5fa7e89ab18",
      "854d927dde2f4651a7ba0d4b9035e3ff",
      "6f10bcb79ed64125b62d45652b6e82e0",
      "130a9dc166e24348a0334693c613a75c",
      "e8cadbb4485e4e1da915f55774ed3090",
      "e1de10e4bdc0474e904b8803d4df7c55",
      "104b1e77c7f949ce8ae6045687f30142",
      "e11e88d2753e49cbb4c6628179632dfe",
      "f09abec84e5743b8b96ab060da6830c0",
      "68530541fc8347d8a112cc95ee51ad64",
      "1dbd2cd51ad1410bae745cc2c9ff335b",
      "879933c92d2a49e9abcf753eff921e0a",
      "3119258c2e1f47beb98b0fbb7c13e124",
      "e70c0027c301410aa6ec3f5998adb9f5",
      "ff6624ca93ed4470980a9a3887553e2b",
      "b1f64dd0c431418a8aa7e6cb4b63099f",
      "23eff27a7cd243558a6a248eadc3f648",
      "12ac1ff728d74730bea9c87a160d9a2b",
      "0c3bd37fbc7b4d09bc002a67bb48cc63",
      "bf37a0eb83b6402fb42be9ac714bf67f",
      "f10454867d7c4daf8cd02e3273114847",
      "ada1521f1f7f4748a44f6dd2dfad5d62",
      "2252da0dd475493c908086d6e43031a6",
      "740645c15e67419789780e119c39bbc1",
      "80857b5ade8141c6a6f175fcfff80f6b",
      "c621f9ec7c404e70859230e5855941d2",
      "c1a5fe9cdda34aaba5989e7a442c5a25",
      "7593f0a77b0a4d1db83f2c536072e972",
      "3e6256c826174d16853e31333f86eee7",
      "b43df83aa7c14b5584aaa77e59f674ff",
      "1b4b73b3fb4944feb244c403057be1ae",
      "4afe980d7b3240a98d7c7400be6c563f",
      "b7f27a44db4e4f01848681fb1dafd891",
      "2a5c671bc4164bcf91b4143252379832",
      "d0d0b6aa3e4b44c7b7d921b392184cf1",
      "0bc6f17896a346bdb44728b5834e073d",
      "3194178de19846d2b843e6b1718cb04b",
      "bd6b0e4bf65845ab84bb41fda90a9521",
      "38c0bc4bddb64291bf5629f95376265f",
      "32fae067c655488ca238bc094e9edf02",
      "91c9a510ba8c469a9bf22cacc561ee88",
      "9ec8a6a7ca6e4089a54e18b869464178",
      "501e55e53f114772a09414b452671ee0",
      "942212df920c478fbd994e5d8da27229",
      "41167edf0ff346758ca60edf031f7f31",
      "9af2a4e03783412897105d494cf83d7e",
      "9eddbad5c6894d04b07e4c43bf54ef4c",
      "ec0af67566454254a861e828abd5a7ea",
      "ae298de517134b7cb834b6952e9e9531",
      "61e2f91d945242b4865c80369163f93e",
      "0c1e7332eff2472689d38744ae68dbdd",
      "3d7bdaa9b4b9499782559d7dc261e74f",
      "37f1fca466144e84a7d9542ddc74076f",
      "c3e14f25971646d197d20c17aa2adac2",
      "2f2af491ddde4f7b9e98a5ab56dd548b",
      "3bb4cfa04a1b4ddcb31ed3a250598bbb",
      "81a87f3b53fd418390ddbbd16818154b",
      "737c860403e343eb8a706ba2b2359f83",
      "88e2fb9106544ad8b61e64ff4909dad1",
      "77c0e629aa6f437d9d4fd598d1c36c9c",
      "af1caa9bda514a1aa38b7ca2333fcce4",
      "56591142b23543dfa24e124ad0f76bf8",
      "c0c43e8ed3d1408aa410d775e82196b9",
      "203bcc2cd0b04beab17aeffd94218a4b",
      "e4b8e4408c964d4c9c0fd0f08a801d53",
      "c72f7bc8ebcb416f88310083a4a3e5fd",
      "c610982ebfcb433ca0d7e1dbfb572260",
      "7f3a044c4ad84c28ad2896cd725c3ce4",
      "aa2aee20a7c04b2cab5a43c17cd46107",
      "a25f0b1939064e448e86eb54f7c78fe9",
      "b0f60415806a4f0a914073e3b36b4e60",
      "9ea81f1a3acc4348b4980e0922878212",
      "3efc9835abd943ad8b2b0baf9fd460d7",
      "448d86b398e048b5aba22b744531e50d",
      "35edd763a28c47d68a4ae7a016341715",
      "5d8a40360a9e4a029d6086c809f6630f",
      "8e033ee11b2649129279d1fbfe087569",
      "7d4616282f3b4380b38492cbac6e0edc"
     ]
    },
    "id": "06bOvL7RwPhn",
    "outputId": "6f140be9-226f-42b1-9ba3-f06b11f3eee9"
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    hp = Hyperparameters()\n",
    "    print_memory_usage(\"Before loading data\")\n",
    "    tfidf_data, train_data, val_data, test_data = prepare_clean_and_tfidf(hp)\n",
    "    print_memory_usage(\"After loading and preprocessing data\")\n",
    "    all_tfidf = run_tfidf_experiments(hp, tfidf_data)\n",
    "    all_trans = run_transformer_experiments(hp, train_data, val_data, test_data)\n",
    "    # merge and print summary\n",
    "    all_results = {**all_tfidf, **all_trans}\n",
    "    # Báo cáo tổng hợp kết quả\n",
    "    print(\"\\n\\n\" + \"=\"*60)\n",
    "    print(\"SUMMARY OF ALL MODEL PERFORMANCES\")\n",
    "    print(\"=\"*60)\n",
    "    for model_name, results in all_results.items():\n",
    "        if results:\n",
    "            print(f\"\\n{model_name}:\")\n",
    "            print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "            if 'report' in results and isinstance(results['report'], dict):\n",
    "                # Xử lý báo cáo cho transformer và TF-IDF\n",
    "                if '0' in results['report'] and '1' in results['report']:\n",
    "                    print(f\"F1-Score (Fake): {results['report']['0']['f1-score']:.4f}\")\n",
    "                    print(f\"F1-Score (True): {results['report']['1']['f1-score']:.4f}\")\n",
    "                elif 'macro avg' in results['report']:\n",
    "                    print(f\"F1-Score (Macro): {results['report']['macro avg']['f1-score']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
